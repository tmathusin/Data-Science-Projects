{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical plots\n",
    "### no predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_plot_no_pred(df, feat_lst, rows, cols, target, y, target_lim = None, output_file='cat_plot'):\n",
    "    i=0\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(rows, cols, figsize= (6*cols, 6*rows))\n",
    "    \n",
    "    for feature in feat_lst:\n",
    "        x= df.groupby(feature, as_index= True)[[target, y]].aggregate({target: 'mean', y: 'sum'})\n",
    "        x= x.rename_axis('bin').reset_index()\n",
    "        \n",
    "        i+=1\n",
    "        ax = plt.subplot(rows, cols, i)\n",
    "        sns.lineplot(data = x[target], marker='o', sort= False, ax=ax)\n",
    "        plt.grid(False)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title(feature)\n",
    "        ax.set_ylim(target_lim)\n",
    "\n",
    "        ax2 = ax.twinx()\n",
    "        sns.barplot(data = x, x='bin', y= y, alpha= .5, ax=ax2)\n",
    "        plt.grid(False)\n",
    "        fig.tight_layout()\n",
    "    fig.savefig(output_file)\n",
    "    fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_plot_with_pred(df, feat_lst, rows, cols, target, y, pred, target_lim = None):\n",
    "    i=0\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(rows, cols, figsize= (6*cols, 6*rows))\n",
    "    \n",
    "    for feature in feat_lst:\n",
    "        x= df.groupby(feature, as_index= True)[[target, pred, y]].aggregate({target: 'mean', pred: 'mean', y: 'sum'})\n",
    "        x= x.rename_axis('bin').reset_index()\n",
    "        \n",
    "        i+=1\n",
    "        ax = plt.subplot(rows, cols, i)\n",
    "        sns.lineplot(data = x[[target, pred]], marker='o', sort= False, ax=ax)\n",
    "        plt.grid(False)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title(feature)\n",
    "        ax.set_ylim(target_lim)\n",
    "\n",
    "        ax2 = ax.twinx()\n",
    "        sns.barplot(data = x, x='bin', y= y, alpha= .5, ax=ax2)\n",
    "        plt.grid(False)\n",
    "        fig.tight_layout()\n",
    "    fig.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical\n",
    "### without predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_plot_no_pred(df, feat_lst, rows, cols, target, y, nbins=10, target_lim = None, output_file='num_plot'):\n",
    "    i=0\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(rows, cols, figsize= (6*cols, 6*rows))\n",
    "    \n",
    "    for feature in feat_lst:\n",
    "        x= df.groupby(pd.qcut(df[feature], nbins, duplicates= 'drop'), as_index= True)[[target, y]].aggregate({target: 'mean', y: 'sum'})\n",
    "        x= x.rename_axis('bin').reset_index()\n",
    "        \n",
    "        i+=1\n",
    "        ax = plt.subplot(rows, cols, i)\n",
    "        sns.lineplot(data = x[target], marker='o', sort= False, ax=ax)\n",
    "        plt.grid(False)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title(feature)\n",
    "        ax.set_ylim(target_lim)\n",
    "\n",
    "        ax2 = ax.twinx()\n",
    "        sns.barplot(data = x, x='bin', y= y, alpha= .5, ax=ax2)\n",
    "        plt.grid(False)\n",
    "        fig.tight_layout()\n",
    "    fig.savefig(output_file)    \n",
    "    fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_plot_with_pred(df, feat_lst, rows, cols, target, y, pred, nbins=10, target_lim = None):\n",
    "    i=0\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(rows, cols, figsize= (6*cols, 6*rows))\n",
    "    \n",
    "    for feature in feat_lst:\n",
    "        x= df.groupby(pd.qcut(df[feature], nbins, duplicates= 'drop'), as_index= True)[[target, pred, y]].aggregate({target: 'mean', pred: 'mean', y: 'sum'})\n",
    "        x= x.rename_axis('bin').reset_index()\n",
    "        \n",
    "        i+=1\n",
    "        ax = plt.subplot(rows, cols, i)\n",
    "        sns.lineplot(data = x[[target, pred]], marker='o', sort= False, ax=ax)\n",
    "        plt.grid(False)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title(feature)\n",
    "        ax.set_ylim(target_lim)\n",
    "\n",
    "        ax2 = ax.twinx()\n",
    "        sns.barplot(data = x, x='bin', y= y, alpha= .5, ax=ax2)\n",
    "        plt.grid(False)\n",
    "        fig.tight_layout()\n",
    "    fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_low_freq(df, lst, pct=1):\n",
    "    for f in lst:\n",
    "        series= pd.value_counts(df[f])\n",
    "        mask= (series/series.sum() * 100).lt(pct)\n",
    "        mode= df[f].mode()[0]\n",
    "        df[f] = np.where(df[f].isin(series[mask].index), mode, df[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz_curve(y_true, y_pred, exposure):\n",
    "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
    "    exposure = np.asarray(exposure)\n",
    "    \n",
    "    ranking = np.argsort(y_pred)\n",
    "    ranked_exposure = exposure[ranking]\n",
    "    ranked_pure_premium = y_true[ranking]\n",
    "    cumulated_claim_amount = np.cumsum(ranked_pure_premium * ranked_exposure)\n",
    "    cumulated_claim_amount = np.true_divide(cumulated_claim_amount, cumulated_claim_amount[-1], out= cumulated_claim_amount, casting='unsafe')\n",
    "    cumulated_samples = np.linspace(0, 1, len(cumulated_claim_amount))\n",
    "    return cumulated_samples, cumulated_claim_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_bubble(df, group, lims= [50, 300]):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "    #   Frequency vs Severity\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    sns.scatterplot(x='Frequency', y=\"Severity\", size=\"Dist\", sizes=(1000, 10000), hue=group, palette=\"ch:r=-.2,d=.3_r\", legend=False, data=df)\n",
    "    plt.title('Frequency vs Severity')\n",
    "\n",
    "    #For each point, we add a text inside the bubble\n",
    "    for line in range(0, df.shape[0]):\n",
    "        ax.text(df.Frequency[line], df.Severity[line], df[group][line], horizontalalignment='center', verticalalignment= 'center', size='medium', color='black')\n",
    "\n",
    "    #   PurePremium vs AvgNetPremium\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    sns.scatterplot(x='PurePremium', y=\"AvgEP\", size=\"Dist\", sizes=(1000, 10000), hue=group, palette=\"ch:r=-.2,d=.3_r\", legend=False, data=df)\n",
    "    plt.xlim(lims)\n",
    "    plt.ylim(lims)\n",
    "    ax.plot(lims, lims, linestyle=\"--\", color=\"black\")\n",
    "    plt.title('PurePremium vs AvgNetPremium')\n",
    "\n",
    "    #For each point, we add a text inside the bubble\n",
    "    for line in range(0, df.shape[0]):\n",
    "        ax.text(df.PurePremium[line], df.AvgEP[line], df[group][line], horizontalalignment='center', verticalalignment= 'center', size='medium', color='black')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def planmaster_date_to_datetime(df, columns):\n",
    "    '''\n",
    "    function to convert Foundation date format to datetime\n",
    "    '''\n",
    "    df_= df.copy()\n",
    "    for c in columns:\n",
    "        df_['datemonth'] = df_[c].astype(int).astype(str).str[-4:]\n",
    "        df_['year'] = df_[c].astype(int).astype(str).str[:3]\n",
    "        df_['year'] = df_['year'].astype(int)+1900\n",
    "        df_[c]= df_['year'].astype(str)+df_['datemonth']\n",
    "        # df_[c] = pd.to_datetime(df_[c], format='%Y%m%d')\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_fix(df, cols):\n",
    "    df[cols] = df[cols].apply(pd.to_datetime)\n",
    "    # df[cols] = df[cols].apply(lambda x: x.dt.date)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_perf_stats(model, train, valid):\n",
    "    # Performance statistics\n",
    "    perf1 = model.model_performance(train)\n",
    "    perf2 = model.model_performance(valid)\n",
    "    metrics_list= ['MCC: {:.5f} / {:.5f}'.format(perf1.mcc()[0][1], perf2.mcc()[0][1]),\n",
    "                   'F1: {:.5f} / {:.5f}'.format(perf1.F1()[0][1], perf2.F1()[0][1]),\n",
    "                   'AUC: {:.5f} / {:.5f}'.format(perf1.auc(), perf2.auc()),\n",
    "                   'AUC PR: {:.5f} / {:.5f}'.format(perf1.aucpr(), perf2.aucpr()),\n",
    "                   'Accuracy: {:.5f} / {:.5f}'.format(perf1.accuracy()[0][1], perf2.accuracy()[0][1]),\n",
    "                   'Logloss: {:.5f} / {:.5f}'.format(perf1.logloss(), perf2.logloss())\n",
    "                #    ,\n",
    "                #    'KS: {:.5f}'.format(model.kolmogorov_smirnov())\n",
    "        ]\n",
    "    return metrics_list\n",
    "\n",
    "def print_model_perf_stats(model, train, valid):\n",
    "    # Performance statistics\n",
    "    perf1 = model.model_performance(train)\n",
    "    perf2 = model.model_performance(valid)\n",
    "    print('MCC: {:.5f} / {:.5f}'.format(perf1.mcc()[0][1], perf2.mcc()[0][1]))\n",
    "    print('F1: {:.5f} / {:.5f}'.format(perf1.F1()[0][1], perf2.F1()[0][1]))\n",
    "    print('AUC: {:.5f} / {:.5f}'.format(perf1.auc(), perf2.auc()))\n",
    "    print('AUC PR: {:.5f} / {:.5f}'.format(perf1.aucpr(), perf2.aucpr()))\n",
    "    print('Accuracy: {:.5f} / {:.5f}'.format(perf1.accuracy()[0][1], perf2.accuracy()[0][1]))\n",
    "    print('Logloss: {:.5f} / {:.5f}'.format(perf1.logloss(), perf2.logloss()))\n",
    "    # print('KS: {:.5f}'.format(model.kolmogorov_smirnov()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_plots(model, df, target):\n",
    "    pred = model.predict(h2o.H2OFrame(df[features + [target]]))['p1'].as_data_frame()\n",
    "    pred = pred.rename(columns= {'p1': 'predictions'})\n",
    "    df_pred= pd.concat([df.reset_index(drop= True), pred.reset_index(drop= True)], axis= 1)\n",
    "\n",
    "    sns.set_style('whitegrid')\n",
    "    fig, ax = plt.subplots(1, 2, figsize= (20, 8))\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    x= df_pred.groupby(pd.qcut(df_pred['predictions'], 20, duplicates= 'drop'), as_index=True, observed=True)[[target, 'predictions']].mean()\n",
    "    x= x.rename_axis('Bin').reset_index()\n",
    "    sns.lineplot(data= x[[target, 'predictions']], lw=2, ax=ax)\n",
    "    \n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    sns.histplot(data= df_pred, x= 'predictions', stat= 'density', ax= ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_leave_one_out(feature, target):\n",
    "    \n",
    "    l1o_encoder = ce.LeaveOneOutEncoder( \n",
    "                                    handle_missing='return_nan',\n",
    "                                    handle_unknown='return_nan',\n",
    "                                    sigma=0.01)\n",
    "    \n",
    "    l1o_encoder.fit(feature,target)\n",
    "    l1o_transformed_feature = l1o_encoder.transform(feature)\n",
    "    \n",
    "    return l1o_encoder, l1o_transformed_feature\n",
    "\n",
    "\n",
    "def get_ordinal(feature):\n",
    "    \n",
    "    ord_encoder = ce.ordinal.OrdinalEncoder( \n",
    "                                    handle_missing='return_nan',\n",
    "                                    handle_unknown='return_nan')\n",
    "    \n",
    "    ord_encoder.fit(feature)\n",
    "    ord_transformed_feature = ord_encoder.transform(feature)\n",
    "    \n",
    "    return ord_encoder, ord_transformed_feature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(df, target, minor_label, major_label):\n",
    "    '''\n",
    "    resample a dataset so its majority class is undersampled to match the count of its\n",
    "    minority class\n",
    "    '''  \n",
    "    seed = 1\n",
    "    \n",
    "    class_counts = df[target].value_counts()\n",
    "    \n",
    "    c1 = df[df[target] == minor_label]\n",
    "    c0 = df[df[target] == major_label]\n",
    "\n",
    "    df_1 = c1.sample(class_counts[minor_label], random_state = seed )\n",
    "    df_0 = c0.sample(class_counts[minor_label])\n",
    "    \n",
    "    sampled_df = pd.concat([df_0, c1],axis=0)\n",
    "        \n",
    "    return sampled_df\n",
    "    \n",
    "def imbalanced_undersample(df, target, minor_label, major_label):\n",
    "    '''\n",
    "    resample a dataset so its majority class is undersampled to double the count of its\n",
    "    minority class\n",
    "    '''  \n",
    "    \n",
    "    class_counts = df[target].value_counts()\n",
    "    \n",
    "    c1 = df[df[target] == minor_label]\n",
    "    c0 = df[df[target] == major_label]\n",
    "\n",
    "    df_1 = c1.sample(class_counts[minor_label])\n",
    "    df_0 = c0.sample(class_counts[minor_label]*2)\n",
    "    \n",
    "    sampled_df = pd.concat([df_0, c1],axis=0)\n",
    "        \n",
    "    return sampled_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "caf1c2fcf97217de91eafa76b907d50f9ea378f5ffbee7f571142d119bb6a771"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
